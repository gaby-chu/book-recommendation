{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-project part III: Research report\n",
    "\n",
    "We've put some effort into building our collection of volumes - you can find them in [this Google Drive folder](https://drive.google.com/drive/u/0/folders/1UAaGIiqElF9YLTGIy6hQYM7QcGzosZgR). Now it's time to learn something about it. You already have lots of excellent ideas for how to apply the tools we've learned about so far. It's also a good time in the semester to review what we have learned and practice applying it in less structured settings.\n",
    "\n",
    "**You will work by yourself or in a group of up to three people** to complete a short project applying methods from the previous weeks to this collection. You will turn in the completed project as a single notebook (one submission per group) with the following sections:\n",
    "\n",
    "0. **Project team.** List members with full names and NetIDs. If your group does not contain at least one native speaker of English, let us know.\n",
    "\n",
    "1. **Question(s) (10 points).** Describe what you wanted to learn. Suggest several possible answers or hypotheses, and describe in general terms what you might expect to see if each of these answers were true (save specific measurements for the next section). For example, many students want to know the difference between horror and non-horror fiction, or between detective stories and horror fiction, but there are many ways to operationalize this question. You do not need to limit yourself to questions of genre. **Note that your question should be interesting! If the answer is obvious before you begin, or if it's something the importance of which you cannot explain, your grade will suffer (a lot).** \n",
    "\n",
    "1. **Methods (10 points).** Describe how you will use computational methods presented so far in this class to answer your question. What do the computational tools do, and how does their output relate to your question? Describe how you will process the collection into a form suitable for a model or algorithm and why you have processed it the way you have.\n",
    "\n",
    "1. **Code (20 points).** Carry out your experiments. Code should be correct (no errors) and focused (unneeded code from examples is removed). Use the notebook format effectively: code may be incorporated into multiple sections.\n",
    "\n",
    "1. **Results and discussion (40 points).** Use sorted lists, tables, and visual presentations to make your argument. Excellent projects will provide multiple views of results, and follow up on any apparent outliers or strange cases, including through careful reading of the original documents.\n",
    "\n",
    "1. **Reflection (10 points).** Describe your experience in this process. What was harder or easier than you expected? What compromises or negotiations did you have to accept to match the collection, the question, and the methods? What would you try next? Your reflections should be written as single narrative that incorporates the viewpoints of all group members.\n",
    "\n",
    "1. **Resources consulted (0 points, but -5 if missing).** Credit any online sources (Stack Overflow, blog posts, documentation, etc.) that you found helpful.\n",
    "\n",
    "1. **Responsibility statement (0 points, but -5 if missing).** See separate CMS assignment \"MP 03: Responsibility statement\". **Note:** If you worked alone on the project (a group of one), you are not required to submit the responsibility statement.\n",
    "\n",
    "\n",
    "## Submission instructions\n",
    "\n",
    "1. Complete this Jupyter Notebook.\n",
    "1. Open a group submission on CMS - Let us know if you encounter any problems with that!\n",
    "1. Assign the role of group submitter to a member of your group.\n",
    "1. Submit the completed Jupyter Notebook in the group submission on CMS.\n",
    "\n",
    "**Note:** If you worked alone on the project (a group of one), you are not required to submit the responsibility statement.\n",
    "\n",
    "Otherwise...\n",
    "\n",
    "1. Go to the CMS assignment 'MP 03: Responsibility statement'.\n",
    "1. Complete the statement, describing each group member's contributions as you see them. \n",
    "1. Upload the statement as an **individual** submission on CMS.\n",
    "\n",
    "\n",
    "## Guidance and advice\n",
    "\n",
    "Show us what you've learned so far. Try to use a range of methods while remaining focused on your chosen problem. For inspiration, consider the range of research problems you've enoucountered in the readings. Note that dictionary-based sentiment scoring projects have not historically done well without substantial additional methodological diversity.\n",
    "\n",
    "**We will grade this work based on accuracy, thoroughness, creativity, reflectiveness, and quality of presentation.** Code and results that are merely correct are generally not enough, on their own, to achieve a high score.\n",
    "\n",
    "**Scope:** this is a *mini*-project, with a short deadline. We are expecting work that is consistent with that timeframe, but that is serious, thoughtful, and rigorous. This assignment will almost certainly require more time and effort than the typical weekly homework. **For group work, the expected scope grows linearly with the number of participants.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Project team\n",
    "\n",
    "Estelle Hooper (ehh52), Gabriella Chu (gc386)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Question(s) (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Research Question: How can we recommend books of other genres to lovers of a single genre?\n",
    "#### Motivation \n",
    "When choosing to consume any form of entertainment, such as a TV show, play, or movie, people tend to favor a particular genre or gravitate towards a favorite story. Unlike the aforementioned examples, people tend to consume books or novels at their own pace, which could be considered more time consuming and costly in terms of mental effort to stay committed to a written story. Because time and attention are scarce, people are more likely to read books of one genre. Many people do not have the capacity to branch out and try new genres, feeling that the safer choice is to read a more predictable book of their favored genre rather than risk not enjoying content of a different genre.\n",
    "#### Hypothesis\n",
    "In order to have confidence in another genre, there must be overlapping qualities between a reader's favorite genre and the new genre. Fans of the horror genre may be fond of the setting because horror fiction can often involve supernatural beings or powers, such as ghosts. Therefore, they may also enjoy science fiction or fantasy that similarly incorporates elements outside of the natural world. Besides content, genres may overlap in how the genre's authors tend to portray characters. Adventure and detective genres tend to involve a partner-in-crime in which the two characters develop strong trust. If the character interactions are important, then perhaps fans of the detective genre would also be a fan of the romance genre since the latter involves the development of a relationship between characters.\n",
    "#### Project\n",
    "Our corpus consists of a good sample of horror novels, detective novels, and a miscellanous group of novels from other genres. We want to see how close these \"other novels\" are to either the horror genre or detective genre. We will train a classifier using the detective and horror novels, and run that classifier on the \"other\" novels. Those \"other\" novels will receive a horror or detective label (despite not being canonically considered part of the horror or detective genres). With these classifier outcomes, we will recommend the \"other\" books labeled \"detective\" to fans of the detective genre and those labeled \"horror\" to the horror genre. For example, the classifier ran on *Harry Potter*, a fantasy series, and gave it a detective label, we would recommend detective fans to read *Harry Potter.*\n",
    "#### Expectations\n",
    "Overall, we don't expect the recommendations we obtain from the classifer to be very great because it is only working with detective and horror, and it will be hard to find overlapping words with only those two genres and the various other genres in the corpus. We expect detective and horror novels with the most subplots and settings similar to other genres to score well with those genres. For example, if detective novels tend to have romance subplots, we expect the classifier to label romance novels as detective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Methods (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Data Preparation\n",
    "From the class corpus, we will divide the novels into two subsets: horror and detective, and the rest of the novels. The horror and detective will act as our \"training\" dataset because we will train the classifier to classify text as either **detective (==1) or horror (==0).** All the other novels of other genres will act as our \"testing\" dataset, and the classifier will predict these novels as either horror or detective. We will use the detective column in the metadata to get the gold labels of the training data in order to score our model later on. We'll also read/open all the novels in this step.\n",
    "### II. Vectorization\n",
    "We will vectorize the novels with tfidf weighting, L2, and z-scores to standardize and normalize our corpus, and consider pre-processing factors like stopwords and lowercasing. Them, we'll create multilple vectorizers with a variety of max input features and fit the training data (true horror and detective). We will try different combinations of these matrices (each with a different number input features) with different types of classifiers in the next step.\n",
    "### III. Classifier\n",
    "We will test different classification methods with different parameters (Multinomial Naive Bayes and Logistic Regression) with our X_train matrix of different sizes and the gold labels (y_train) and compare the accuracy/precision/recall/F1 scores and select the best classifier.\n",
    "### IV. Feature Importance \n",
    "After finding the model with the best F1 score, we will examine the words/tokens/features with the heaviest weights that aid in classifying a work as detective or horror. If we see odd words, such as character names, or common stopwords as the top features, we will reconsider our vectorization steps.\n",
    "### V. Testing/Predicting\n",
    "After finalizing our classifier, we will run it on our testing data, or the novels of other genres without detective or horror labels. From this classifier, each \"other\" novel will receive a horror or detective label (y_test).\n",
    "### VI. Scatterplots/Visualizations (to be discussed in Part 4: Results)\n",
    "Because the classifier only makes binary decisions, we want to examine the most \"detective-y\" and \"horror-y\" novels because there will be some novels that the classifer could not make as definitive decisions for. We will use SVD to graph all the novels in 2D space. We will then create multiple scatterplots to look at these decision boundaries. The most important scatterplots will be the ones that look at how close the true labeled novels are to the predicted  novels are in distance space. We will consider the predicted dots that are closest to the true dots to be the best recommendations for that genre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Code (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports (all of them!)\n",
    "%matplotlib inline\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "from   sklearn.decomposition import TruncatedSVD\n",
    "from   sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from   sklearn.preprocessing import StandardScaler, MinMaxScaler, normalize\n",
    "from   sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Data Preparation\n",
    "In this section, we cleaned and manipulated the class metadata in order to subset the data into training and testing. As stated previously, our training data is all horror or detective, and our testing is all other books that are not horror and detective. The following is a list of variables that we created to accomplish in order to proceed with vectorization. Besides subsetting, the most notable tasks we did were sorting the dataframes by title in alphabetical order and obtaining the gold labels (y_train), which will be used to cross_validate our model when we build our classifer. \n",
    "- `metadata` df; metadata spreadsheet from class corpus\n",
    "- `training_data` df; metadata with training novels, received by subsetting metadata Detective==True | Horror==True\n",
    "- `testing_data` df; metadata with testing novels, received by subsetting metadata Detective==True & Horror==True\n",
    "- `training_names` list; list of filenames, recieved by training_data.filename.values\n",
    "- `testing_names` list; list of filenames, recieved by testing_data.filename.values\n",
    "- `training_books` list; list of strings/books, recieved by reading files using training_names\n",
    "- `testing_books` list; list of strings/books, recieved by reading files using testing_names\n",
    "- `y_train` list; the **gold labels (1=detective, 0=horror)**, or true values of the training data, obtained from the training_data detective column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 34)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class corpus metadata\n",
    "metadata = pd.read_csv(\"class_corpus_metadata.csv\")\n",
    "metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>check_1</th>\n",
       "      <th>check_2</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>author1_surname</th>\n",
       "      <th>author1_givenname</th>\n",
       "      <th>author2_surname</th>\n",
       "      <th>author2_givenname</th>\n",
       "      <th>gender_author1</th>\n",
       "      <th>...</th>\n",
       "      <th>feminist fiction</th>\n",
       "      <th>mystery</th>\n",
       "      <th>adventure</th>\n",
       "      <th>tragedy</th>\n",
       "      <th>children</th>\n",
       "      <th>regency</th>\n",
       "      <th>manners</th>\n",
       "      <th>philosophical</th>\n",
       "      <th>coming-of-age</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nsg57</td>\n",
       "      <td>scw222</td>\n",
       "      <td>lcc82</td>\n",
       "      <td>Writings in the United Amateur, 1915 - 1922</td>\n",
       "      <td>1922</td>\n",
       "      <td>Lovecraft</td>\n",
       "      <td>Howard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Lovecraft_WritingsintheUnitedAmateur1915-1922.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fhh26</td>\n",
       "      <td>gs542</td>\n",
       "      <td>tj256</td>\n",
       "      <td>Whose Body?</td>\n",
       "      <td>1923</td>\n",
       "      <td>Sayers</td>\n",
       "      <td>Dorothy L.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sayres_WhoseBody.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cl2264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Voodoo Planet</td>\n",
       "      <td>1959</td>\n",
       "      <td>Norton</td>\n",
       "      <td>Andre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Norton_VoodooPlanet.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ehh52</td>\n",
       "      <td>sjr255</td>\n",
       "      <td>kg428</td>\n",
       "      <td>Varney the Vampire; Or, the Feast of Blood by ...</td>\n",
       "      <td>1845</td>\n",
       "      <td>Rymer</td>\n",
       "      <td>James Malcolm</td>\n",
       "      <td>Prest</td>\n",
       "      <td>Thomas Peckett</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Prest_Rhymer_VarneyTheVampire.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dgr73</td>\n",
       "      <td>jlp367</td>\n",
       "      <td>kg428</td>\n",
       "      <td>Uncle Tom's Cabin</td>\n",
       "      <td>1852</td>\n",
       "      <td>Stowe</td>\n",
       "      <td>Harriet Beecher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Stowe_UncleTom_sCabin.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0 check_1 check_2  \\\n",
       "0      nsg57  scw222   lcc82   \n",
       "1      fhh26   gs542   tj256   \n",
       "2     cl2264     NaN     NaN   \n",
       "3      ehh52  sjr255   kg428   \n",
       "4      dgr73  jlp367   kg428   \n",
       "\n",
       "                                               title  year author1_surname  \\\n",
       "0        Writings in the United Amateur, 1915 - 1922  1922       Lovecraft   \n",
       "1                                        Whose Body?  1923          Sayers   \n",
       "2                                      Voodoo Planet  1959          Norton   \n",
       "3  Varney the Vampire; Or, the Feast of Blood by ...  1845           Rymer   \n",
       "4                                  Uncle Tom's Cabin  1852           Stowe   \n",
       "\n",
       "  author1_givenname author2_surname author2_givenname gender_author1  ...  \\\n",
       "0            Howard             NaN               NaN           Male  ...   \n",
       "1        Dorothy L.             NaN               NaN         Female  ...   \n",
       "2             Andre             NaN               NaN         Female  ...   \n",
       "3     James Malcolm           Prest    Thomas Peckett           Male  ...   \n",
       "4   Harriet Beecher             NaN               NaN         Female  ...   \n",
       "\n",
       "  feminist fiction mystery adventure tragedy children  regency  manners  \\\n",
       "0            False    True     False   False    False    False    False   \n",
       "1            False    True     False   False    False    False    False   \n",
       "2            False   False      True   False    False    False    False   \n",
       "3            False   False     False   False    False    False    False   \n",
       "4            False   False     False   False    False    False    False   \n",
       "\n",
       "  philosophical coming-of-age  \\\n",
       "0          True         False   \n",
       "1         False         False   \n",
       "2         False         False   \n",
       "3         False         False   \n",
       "4         False         False   \n",
       "\n",
       "                                            filename  \n",
       "0  Lovecraft_WritingsintheUnitedAmateur1915-1922.txt  \n",
       "1                               Sayres_WhoseBody.txt  \n",
       "2                            Norton_VoodooPlanet.txt  \n",
       "3                  Prest_Rhymer_VarneyTheVampire.txt  \n",
       "4                          Stowe_UncleTom_sCabin.txt  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data are books that are either horror or detective\n",
    "training_data = metadata[(metadata['horror']==True) | (metadata['detective']==True)]\n",
    "\n",
    "# drop books that are both horror and detective\n",
    "drop = metadata[(metadata['horror']==True) & (metadata['detective']==True)]\n",
    "training_data = training_data.drop(drop.index)\n",
    "\n",
    "# testing data are books are neither horror or detective\n",
    "testing_data = metadata[(metadata['horror']==False) & (metadata['detective']==False)]\n",
    "\n",
    "# sort titles alphabetically \n",
    "training_data = training_data.sort_values('title')\n",
    "testing_data = testing_data.sort_values('title')\n",
    "# note: training+testing+dropped row = 159 rows, class corpus = 160 rows, \"An Unkindness of Ghosts\" has no input for horror and detective column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are 80 combined horror and detective novels in the corpus that we will use to train the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>check_1</th>\n",
       "      <th>check_2</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>author1_surname</th>\n",
       "      <th>author1_givenname</th>\n",
       "      <th>author2_surname</th>\n",
       "      <th>author2_givenname</th>\n",
       "      <th>gender_author1</th>\n",
       "      <th>...</th>\n",
       "      <th>feminist fiction</th>\n",
       "      <th>mystery</th>\n",
       "      <th>adventure</th>\n",
       "      <th>tragedy</th>\n",
       "      <th>children</th>\n",
       "      <th>regency</th>\n",
       "      <th>manners</th>\n",
       "      <th>philosophical</th>\n",
       "      <th>coming-of-age</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tl566</td>\n",
       "      <td>hz542</td>\n",
       "      <td>ja532</td>\n",
       "      <td>813</td>\n",
       "      <td>1910</td>\n",
       "      <td>Leblanc</td>\n",
       "      <td>Maurice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Leblanc_813.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gc386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A Strange Disappearance</td>\n",
       "      <td>1998</td>\n",
       "      <td>Green</td>\n",
       "      <td>Anna Katharine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>GreenAnnaKatharine_AStrangeDisappearance.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nca28</td>\n",
       "      <td>tl566</td>\n",
       "      <td>stw43</td>\n",
       "      <td>A Study in Scarlet</td>\n",
       "      <td>1887</td>\n",
       "      <td>Conan Doyle</td>\n",
       "      <td>Arthur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ConanDoyle_AStudyInScarlet.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jc2739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Agatha Webb</td>\n",
       "      <td>1899</td>\n",
       "      <td>Green</td>\n",
       "      <td>Anna Katharine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Green_AgathaWebb.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lcc82</td>\n",
       "      <td>yk499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carmilla</td>\n",
       "      <td>1872</td>\n",
       "      <td>Le_Fanu</td>\n",
       "      <td>Joseph Sheridan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Carmilla.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>tr333</td>\n",
       "      <td>sjs457</td>\n",
       "      <td>sl2324</td>\n",
       "      <td>The Valley of Fear</td>\n",
       "      <td>1915</td>\n",
       "      <td>Doyle</td>\n",
       "      <td>Arthur Conan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Doyle_TheValleyOfFear.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>lrs263</td>\n",
       "      <td>sh785</td>\n",
       "      <td>hz542</td>\n",
       "      <td>The Wisdom of Father Brown</td>\n",
       "      <td>1914</td>\n",
       "      <td>Chesterton</td>\n",
       "      <td>Gilbert Keith</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Chesterton_TheWisdomOfFatherBrown.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>ehh52</td>\n",
       "      <td>sjr255</td>\n",
       "      <td>kg428</td>\n",
       "      <td>Varney the Vampire; Or, the Feast of Blood by ...</td>\n",
       "      <td>1845</td>\n",
       "      <td>Rymer</td>\n",
       "      <td>James Malcolm</td>\n",
       "      <td>Prest</td>\n",
       "      <td>Thomas Peckett</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Prest_Rhymer_VarneyTheVampire.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>fhh26</td>\n",
       "      <td>gs542</td>\n",
       "      <td>tj256</td>\n",
       "      <td>Whose Body?</td>\n",
       "      <td>1923</td>\n",
       "      <td>Sayers</td>\n",
       "      <td>Dorothy L.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sayres_WhoseBody.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>nsg57</td>\n",
       "      <td>scw222</td>\n",
       "      <td>lcc82</td>\n",
       "      <td>Writings in the United Amateur, 1915 - 1922</td>\n",
       "      <td>1922</td>\n",
       "      <td>Lovecraft</td>\n",
       "      <td>Howard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Lovecraft_WritingsintheUnitedAmateur1915-1922.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 check_1 check_2  \\\n",
       "0       tl566   hz542   ja532   \n",
       "1       gc386     NaN     NaN   \n",
       "2       nca28   tl566   stw43   \n",
       "3      jc2739     NaN     NaN   \n",
       "4       lcc82   yk499     NaN   \n",
       "..        ...     ...     ...   \n",
       "75      tr333  sjs457  sl2324   \n",
       "76     lrs263   sh785   hz542   \n",
       "77      ehh52  sjr255   kg428   \n",
       "78      fhh26   gs542   tj256   \n",
       "79      nsg57  scw222   lcc82   \n",
       "\n",
       "                                                title  year author1_surname  \\\n",
       "0                                                 813  1910         Leblanc   \n",
       "1                             A Strange Disappearance  1998           Green   \n",
       "2                                  A Study in Scarlet  1887     Conan Doyle   \n",
       "3                                         Agatha Webb  1899           Green   \n",
       "4                                            Carmilla  1872         Le_Fanu   \n",
       "..                                                ...   ...             ...   \n",
       "75                                 The Valley of Fear  1915           Doyle   \n",
       "76                         The Wisdom of Father Brown  1914      Chesterton   \n",
       "77  Varney the Vampire; Or, the Feast of Blood by ...  1845           Rymer   \n",
       "78                                        Whose Body?  1923          Sayers   \n",
       "79        Writings in the United Amateur, 1915 - 1922  1922       Lovecraft   \n",
       "\n",
       "   author1_givenname author2_surname author2_givenname gender_author1  ...  \\\n",
       "0            Maurice             NaN               NaN           Male  ...   \n",
       "1     Anna Katharine             NaN               NaN         Female  ...   \n",
       "2             Arthur             NaN               NaN           Male  ...   \n",
       "3     Anna Katharine             NaN               NaN         Female  ...   \n",
       "4    Joseph Sheridan             NaN               NaN           Male  ...   \n",
       "..               ...             ...               ...            ...  ...   \n",
       "75      Arthur Conan             NaN               NaN           Male  ...   \n",
       "76     Gilbert Keith             NaN               NaN           Male  ...   \n",
       "77     James Malcolm           Prest    Thomas Peckett           Male  ...   \n",
       "78        Dorothy L.             NaN               NaN         Female  ...   \n",
       "79            Howard             NaN               NaN           Male  ...   \n",
       "\n",
       "   feminist fiction mystery adventure tragedy children  regency  manners  \\\n",
       "0             False    True     False   False    False    False    False   \n",
       "1             False    True     False   False    False    False    False   \n",
       "2             False    True     False   False    False    False    False   \n",
       "3             False    True     False   False    False    False    False   \n",
       "4             False   False     False   False    False    False    False   \n",
       "..              ...     ...       ...     ...      ...      ...      ...   \n",
       "75            False   False     False   False    False    False    False   \n",
       "76            False   False     False   False    False    False    False   \n",
       "77            False   False     False   False    False    False    False   \n",
       "78            False    True     False   False    False    False    False   \n",
       "79            False    True     False   False    False    False    False   \n",
       "\n",
       "   philosophical coming-of-age  \\\n",
       "0          False         False   \n",
       "1          False         False   \n",
       "2          False         False   \n",
       "3          False         False   \n",
       "4          False         False   \n",
       "..           ...           ...   \n",
       "75         False         False   \n",
       "76         False         False   \n",
       "77         False         False   \n",
       "78         False         False   \n",
       "79          True         False   \n",
       "\n",
       "                                             filename  \n",
       "0                                     Leblanc_813.txt  \n",
       "1        GreenAnnaKatharine_AStrangeDisappearance.txt  \n",
       "2                      ConanDoyle_AStudyInScarlet.txt  \n",
       "3                                Green_AgathaWebb.txt  \n",
       "4                                        Carmilla.txt  \n",
       "..                                                ...  \n",
       "75                          Doyle_TheValleyOfFear.txt  \n",
       "76              Chesterton_TheWisdomOfFatherBrown.txt  \n",
       "77                  Prest_Rhymer_VarneyTheVampire.txt  \n",
       "78                               Sayres_WhoseBody.txt  \n",
       "79  Lovecraft_WritingsintheUnitedAmateur1915-1922.txt  \n",
       "\n",
       "[80 rows x 34 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data=training_data.reset_index(drop=True)\n",
    "training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are 78 combined novels from a variety of genres that are not horror or detective in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>check_1</th>\n",
       "      <th>check_2</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>author1_surname</th>\n",
       "      <th>author1_givenname</th>\n",
       "      <th>author2_surname</th>\n",
       "      <th>author2_givenname</th>\n",
       "      <th>gender_author1</th>\n",
       "      <th>...</th>\n",
       "      <th>feminist fiction</th>\n",
       "      <th>mystery</th>\n",
       "      <th>adventure</th>\n",
       "      <th>tragedy</th>\n",
       "      <th>children</th>\n",
       "      <th>regency</th>\n",
       "      <th>manners</th>\n",
       "      <th>philosophical</th>\n",
       "      <th>coming-of-age</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tr333</td>\n",
       "      <td>sjs457</td>\n",
       "      <td>sl2324</td>\n",
       "      <td>A Round Dozen</td>\n",
       "      <td>1883</td>\n",
       "      <td>Coolidge</td>\n",
       "      <td>Susan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Coolidge_ARoundDozen.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kwy3</td>\n",
       "      <td>cl922</td>\n",
       "      <td>hk627</td>\n",
       "      <td>A Sicillian Romance</td>\n",
       "      <td>1790</td>\n",
       "      <td>Radcliffe</td>\n",
       "      <td>Ann Ward</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>radcliffeann_a_sicillian_romance.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lqz4</td>\n",
       "      <td>gt294</td>\n",
       "      <td>lcc82</td>\n",
       "      <td>Adele Doring at Boarding-School</td>\n",
       "      <td>1921</td>\n",
       "      <td>North</td>\n",
       "      <td>Grace May</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>adele_doring_boarding_school.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yc2669</td>\n",
       "      <td>xf89</td>\n",
       "      <td>wms87</td>\n",
       "      <td>Agnes Grey</td>\n",
       "      <td>1847</td>\n",
       "      <td>Bronte</td>\n",
       "      <td>Anne</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Bronte_AgnesGrey.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mn454</td>\n",
       "      <td>ar2465</td>\n",
       "      <td>jlp367</td>\n",
       "      <td>An Old-Fashioned Girl</td>\n",
       "      <td>1869</td>\n",
       "      <td>Alcott</td>\n",
       "      <td>Louisa May</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Alcott_AnOld-FashionedGirl.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>jc2739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This Side of Paradise</td>\n",
       "      <td>1920</td>\n",
       "      <td>Fitzgerald</td>\n",
       "      <td>F. Scott</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Fitzgerald_ThisSideOfParadise.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>vs339</td>\n",
       "      <td>thh55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Kill A Mockingbird</td>\n",
       "      <td>1960</td>\n",
       "      <td>Lee</td>\n",
       "      <td>Harper</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Lee_ToKillAMockingbird.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>fhh26</td>\n",
       "      <td>gs542</td>\n",
       "      <td>tj256</td>\n",
       "      <td>Twenty Thousand Leagues Under the Sea</td>\n",
       "      <td>1870</td>\n",
       "      <td>Verne</td>\n",
       "      <td>Jules</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Verne_TwentyThousandLeagues.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>dgr73</td>\n",
       "      <td>jlp367</td>\n",
       "      <td>kg428</td>\n",
       "      <td>Uncle Tom's Cabin</td>\n",
       "      <td>1852</td>\n",
       "      <td>Stowe</td>\n",
       "      <td>Harriet Beecher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Stowe_UncleTom_sCabin.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>cl2264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Voodoo Planet</td>\n",
       "      <td>1959</td>\n",
       "      <td>Norton</td>\n",
       "      <td>Andre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Norton_VoodooPlanet.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 check_1 check_2                                  title  year  \\\n",
       "0       tr333  sjs457  sl2324                          A Round Dozen  1883   \n",
       "1        kwy3   cl922   hk627                    A Sicillian Romance  1790   \n",
       "2        lqz4   gt294   lcc82        Adele Doring at Boarding-School  1921   \n",
       "3      yc2669    xf89   wms87                             Agnes Grey  1847   \n",
       "4       mn454  ar2465  jlp367                  An Old-Fashioned Girl  1869   \n",
       "..        ...     ...     ...                                    ...   ...   \n",
       "73     jc2739     NaN     NaN                  This Side of Paradise  1920   \n",
       "74      vs339   thh55     NaN                  To Kill A Mockingbird  1960   \n",
       "75      fhh26   gs542   tj256  Twenty Thousand Leagues Under the Sea  1870   \n",
       "76      dgr73  jlp367   kg428                      Uncle Tom's Cabin  1852   \n",
       "77     cl2264     NaN     NaN                          Voodoo Planet  1959   \n",
       "\n",
       "   author1_surname author1_givenname author2_surname author2_givenname  \\\n",
       "0         Coolidge             Susan             NaN               NaN   \n",
       "1        Radcliffe          Ann Ward             NaN               NaN   \n",
       "2            North         Grace May             NaN               NaN   \n",
       "3           Bronte              Anne             NaN               NaN   \n",
       "4           Alcott        Louisa May             NaN               NaN   \n",
       "..             ...               ...             ...               ...   \n",
       "73      Fitzgerald          F. Scott             NaN               NaN   \n",
       "74             Lee            Harper             NaN               NaN   \n",
       "75           Verne             Jules             NaN               NaN   \n",
       "76           Stowe   Harriet Beecher             NaN               NaN   \n",
       "77          Norton             Andre             NaN               NaN   \n",
       "\n",
       "   gender_author1  ... feminist fiction mystery adventure tragedy children  \\\n",
       "0          Female  ...            False   False     False   False    False   \n",
       "1          Female  ...            False   False     False   False    False   \n",
       "2          Female  ...            False   False     False   False     True   \n",
       "3          Female  ...             True   False     False   False    False   \n",
       "4          Female  ...            False   False     False   False     True   \n",
       "..            ...  ...              ...     ...       ...     ...      ...   \n",
       "73           Male  ...            False   False     False   False    False   \n",
       "74         Female  ...            False   False     False   False    False   \n",
       "75           Male  ...            False   False      True   False    False   \n",
       "76         Female  ...            False   False     False   False    False   \n",
       "77         Female  ...            False   False      True   False    False   \n",
       "\n",
       "    regency  manners philosophical coming-of-age  \\\n",
       "0     False    False         False         False   \n",
       "1     False    False         False         False   \n",
       "2     False    False         False         False   \n",
       "3     False     True         False         False   \n",
       "4     False     True         False          True   \n",
       "..      ...      ...           ...           ...   \n",
       "73    False    False         False          True   \n",
       "74    False    False         False         False   \n",
       "75    False    False         False         False   \n",
       "76    False    False         False         False   \n",
       "77    False    False         False         False   \n",
       "\n",
       "                                filename  \n",
       "0               Coolidge_ARoundDozen.txt  \n",
       "1   radcliffeann_a_sicillian_romance.txt  \n",
       "2       adele_doring_boarding_school.txt  \n",
       "3                   Bronte_AgnesGrey.txt  \n",
       "4         Alcott_AnOld-FashionedGirl.txt  \n",
       "..                                   ...  \n",
       "73     Fitzgerald_ThisSideOfParadise.txt  \n",
       "74            Lee_ToKillAMockingbird.txt  \n",
       "75       Verne_TwentyThousandLeagues.txt  \n",
       "76             Stowe_UncleTom_sCabin.txt  \n",
       "77               Norton_VoodooPlanet.txt  \n",
       "\n",
       "[78 rows x 34 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data=testing_data.reset_index(drop=True)\n",
    "testing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening book files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get book file names to open\n",
    "training_names = training_data.filename.values\n",
    "testing_names = testing_data.filename.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First book in the training dataset: Leblanc_813.txt\n",
      "First book in the testing dataset: Coolidge_ARoundDozen.txt\n"
     ]
    }
   ],
   "source": [
    "print('First book in the training dataset:',training_names[0])\n",
    "print('First book in the testing dataset:',testing_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1=detective, 0=horror， gold labels\n",
    "y_train=(training_data.detective.values*1).astype('int')\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open and append training books together\n",
    "training_books=[]\n",
    "for book in training_names:\n",
    "    with open(book, 'r',encoding='utf-8') as f:\n",
    "        file = f.read().replace(\"\\n\", \" \") \n",
    "        training_books.append(file)\n",
    "# open and append testing books together\n",
    "testing_books=[]\n",
    "for book in testing_names:\n",
    "    with open(book, 'r',encoding='utf-8') as f:\n",
    "        file = f.read().replace(\"\\n\", \" \") \n",
    "        testing_books.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Vectorization, stopwords, normalization, standardization, matrix fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords\n",
    "We played around with using stopwords and changing the max_df parameter in the TfidfVectorizer(). We initially did use punctuation as stopwords and compared the matrix with and without using that parameter, and the resulting shape was the same. Given that result, we decided to ignore the stop_words parameter and let the idf weighting take care of the normalization, in addition to L2. We picked L2 normalization over L1 because...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct=[]\n",
    "for x in string.punctuation:\n",
    "    punct.append(x)\n",
    "punct.append('--')\n",
    "punct.append('`')\n",
    "punct.append(\"“\")\n",
    "punct.append(\"”\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization (+ normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix shape: (80, 30376)\n"
     ]
    }
   ],
   "source": [
    "# Custom preprocessing to remove escaped characters in input, taken from MP02\n",
    "def pre_proc(x):\n",
    "    '''\n",
    "    Takes a unicode string.\n",
    "    Lowercases, strips accents, and removes some escapes.\n",
    "    Returns a standardized version of the string.\n",
    "    '''\n",
    "    import unicodedata\n",
    "    return unicodedata.normalize('NFKD', x.replace(\"\\'\", \"'\").replace(\"\\ in\\ form\", \" inform\").lower().strip())\n",
    "\n",
    "# Set up vectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    encoding='utf-8',\n",
    "    preprocessor=pre_proc,\n",
    "   # stop_words=punct,\n",
    "    min_df=2, # Note this\n",
    "    max_df=0.8, # This, too\n",
    "    binary=False,\n",
    "    norm='l2',\n",
    "    use_idf=True, # And this,\n",
    "    #max_features=10000\n",
    ")\n",
    "\n",
    "# Your code here\n",
    "X_train = vectorizer.fit_transform(training_books)\n",
    "print(\"Matrix shape:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization: Z-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<80x30376 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 376031 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z-scored l2 mean: 0.292\n"
     ]
    }
   ],
   "source": [
    "#standardization\n",
    "X_train_Z = StandardScaler(with_mean=False).fit_transform(X_train)\n",
    "display(X_train_Z)\n",
    "print('z-scored l2 mean:', round(np.mean(X_train_Z),3))\n",
    "#np.std(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_n=[]\n",
    "matrix_n= {}\n",
    "feat_n = [5000,10000,15000,17500,20000,22500,25000,30000,35000] # NOTE, get all the features we had to use a value greater than the number of features. So 35000 is actually just all features\n",
    "for x in feat_n:\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        encoding='utf-8',\n",
    "        preprocessor=pre_proc,\n",
    "        min_df=2, # Note this\n",
    "        max_df=0.8, # This, too\n",
    "        binary=False,\n",
    "        norm='l2',\n",
    "        use_idf=True, # And this\n",
    "        max_features=x)\n",
    "    vect_n.append(vectorizer)\n",
    "    matrix = vectorizer.fit_transform(training_books)\n",
    "    X_train_Z = StandardScaler(with_mean=False).fit_transform(matrix)\n",
    "    dict_key=str(x)\n",
    "    matrix_n[dict_key] = X_train_Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'5000': <80x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 187794 stored elements in Compressed Sparse Row format>,\n",
       " '10000': <80x10000 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 274957 stored elements in Compressed Sparse Row format>,\n",
       " '15000': <80x15000 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 320917 stored elements in Compressed Sparse Row format>,\n",
       " '17500': <80x17500 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 335934 stored elements in Compressed Sparse Row format>,\n",
       " '20000': <80x20000 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 347813 stored elements in Compressed Sparse Row format>,\n",
       " '22500': <80x22500 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 357000 stored elements in Compressed Sparse Row format>,\n",
       " '25000': <80x25000 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 364318 stored elements in Compressed Sparse Row format>,\n",
       " '30000': <80x30000 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 375279 stored elements in Compressed Sparse Row format>,\n",
       " '35000': <80x30376 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 376031 stored elements in Compressed Sparse Row format>}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the performance of our simple classifiers\n",
    "# Freebie function to summarize and display classifier scores\n",
    "# source: mp2\n",
    "def compare_scores(scores_dict):\n",
    "    '''\n",
    "    Takes a dictionary of cross_validate scores.\n",
    "    Returns a color-coded Pandas dataframe that summarizes those scores.\n",
    "    '''\n",
    "    df = pd.DataFrame(scores_dict).T.applymap(np.mean).style.background_gradient(cmap='RdYlGn')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6fa4e_row0_col0, #T_6fa4e_row0_col1 {\n",
       "  background-color: #006837;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6fa4e_row0_col2, #T_6fa4e_row0_col3, #T_6fa4e_row0_col4, #T_6fa4e_row0_col5, #T_6fa4e_row0_col6, #T_6fa4e_row0_col7, #T_6fa4e_row1_col0, #T_6fa4e_row1_col1, #T_6fa4e_row1_col2, #T_6fa4e_row1_col3, #T_6fa4e_row1_col4, #T_6fa4e_row1_col5, #T_6fa4e_row1_col6, #T_6fa4e_row1_col7 {\n",
       "  background-color: #a50026;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6fa4e_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >fit_time</th>\n",
       "      <th class=\"col_heading level0 col1\" >score_time</th>\n",
       "      <th class=\"col_heading level0 col2\" >test_accuracy</th>\n",
       "      <th class=\"col_heading level0 col3\" >test_precision</th>\n",
       "      <th class=\"col_heading level0 col4\" >test_recall</th>\n",
       "      <th class=\"col_heading level0 col5\" >test_f1</th>\n",
       "      <th class=\"col_heading level0 col6\" >test_f1_macro</th>\n",
       "      <th class=\"col_heading level0 col7\" >test_f1_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6fa4e_level0_row0\" class=\"row_heading level0 row0\" >M NB Default, Alpha=1</th>\n",
       "      <td id=\"T_6fa4e_row0_col0\" class=\"data row0 col0\" >0.013639</td>\n",
       "      <td id=\"T_6fa4e_row0_col1\" class=\"data row0 col1\" >0.012266</td>\n",
       "      <td id=\"T_6fa4e_row0_col2\" class=\"data row0 col2\" >0.887500</td>\n",
       "      <td id=\"T_6fa4e_row0_col3\" class=\"data row0 col3\" >0.868095</td>\n",
       "      <td id=\"T_6fa4e_row0_col4\" class=\"data row0 col4\" >0.980000</td>\n",
       "      <td id=\"T_6fa4e_row0_col5\" class=\"data row0 col5\" >0.917879</td>\n",
       "      <td id=\"T_6fa4e_row0_col6\" class=\"data row0 col6\" >0.867273</td>\n",
       "      <td id=\"T_6fa4e_row0_col7\" class=\"data row0 col7\" >0.887500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6fa4e_level0_row1\" class=\"row_heading level0 row1\" >M NB fit_prior=False</th>\n",
       "      <td id=\"T_6fa4e_row1_col0\" class=\"data row1 col0\" >0.011189</td>\n",
       "      <td id=\"T_6fa4e_row1_col1\" class=\"data row1 col1\" >0.009851</td>\n",
       "      <td id=\"T_6fa4e_row1_col2\" class=\"data row1 col2\" >0.887500</td>\n",
       "      <td id=\"T_6fa4e_row1_col3\" class=\"data row1 col3\" >0.868095</td>\n",
       "      <td id=\"T_6fa4e_row1_col4\" class=\"data row1 col4\" >0.980000</td>\n",
       "      <td id=\"T_6fa4e_row1_col5\" class=\"data row1 col5\" >0.917879</td>\n",
       "      <td id=\"T_6fa4e_row1_col6\" class=\"data row1 col6\" >0.867273</td>\n",
       "      <td id=\"T_6fa4e_row1_col7\" class=\"data row1 col7\" >0.887500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19ea2ef9b50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifiers = {\n",
    "    'M NB Default, Alpha=1':MultinomialNB(alpha = 1),\n",
    "    'M NB fit_prior=False':MultinomialNB(fit_prior = False),\n",
    "}\n",
    "scores = {} # Store cross-validation results in a dictionary\n",
    "for classifier in nb_classifiers: \n",
    "    scores[classifier] = cross_validate( # perform cross-validation\n",
    "        nb_classifiers[classifier], # classifier object\n",
    "        X_train_Z, # feature matrix\n",
    "        y_train, # gold labels\n",
    "        cv=10, #number of folds\n",
    "        scoring=['accuracy','precision', 'recall', 'f1', 'f1_macro', 'f1_micro'] # scoring methods\n",
    "    )\n",
    "       \n",
    "compare_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 5000)\n",
      "(80, 10000)\n",
      "(80, 15000)\n",
      "(80, 17500)\n",
      "(80, 20000)\n",
      "(80, 22500)\n",
      "(80, 25000)\n",
      "(80, 30000)\n",
      "(80, 30376)\n"
     ]
    }
   ],
   "source": [
    "scores = {} # Store cross-validation results in a dictionary\n",
    "for matrix in matrix_n: \n",
    "    print(matrix_n[matrix].shape)\n",
    "    scores[matrix] = cross_validate( # perform cross-validation\n",
    "        MultinomialNB(alpha = 1), # classifier object\n",
    "        matrix_n[matrix], # feature matrix\n",
    "        y_train, # gold labels\n",
    "        cv=10, #number of folds\n",
    "        scoring=['accuracy','precision', 'recall', 'f1', 'f1_macro', 'f1_micro'] # scoring methods\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f2427_row0_col0, #T_f2427_row0_col1, #T_f2427_row0_col4, #T_f2427_row1_col4, #T_f2427_row5_col2, #T_f2427_row5_col3, #T_f2427_row5_col4, #T_f2427_row5_col5, #T_f2427_row5_col6, #T_f2427_row5_col7, #T_f2427_row6_col4, #T_f2427_row7_col4, #T_f2427_row8_col4 {\n",
       "  background-color: #a50026;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2427_row0_col2, #T_f2427_row0_col7, #T_f2427_row1_col2, #T_f2427_row1_col7, #T_f2427_row4_col2, #T_f2427_row4_col7, #T_f2427_row7_col2, #T_f2427_row7_col7, #T_f2427_row8_col2, #T_f2427_row8_col7 {\n",
       "  background-color: #b7e075;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2427_row0_col3, #T_f2427_row1_col3, #T_f2427_row7_col3, #T_f2427_row8_col3 {\n",
       "  background-color: #87cb67;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2427_row0_col5, #T_f2427_row1_col5, #T_f2427_row7_col5, #T_f2427_row8_col5 {\n",
       "  background-color: #ecf7a6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2427_row0_col6, #T_f2427_row1_col6, #T_f2427_row7_col6, #T_f2427_row8_col6 {\n",
       "  background-color: #51b35e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2427_row1_col0 {\n",
       "  background-color: #f8864f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2427_row1_col1 {\n",
       "  background-color: #f88c51;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2427_row2_col0, #T_f2427_row6_col3 {\n",
       "  background-color: #fed27f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2427_row2_col1 {\n",
       "  background-color: #de402e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2427_row2_col2, #T_f2427_row2_col7, #T_f2427_row6_col2, #T_f2427_row6_col7 {\n",
       "  background-color: #fdbf6f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2427_row2_col3 {\n",
       "  background-color: #d83128;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2427_row2_col4, #T_f2427_row3_col2, #T_f2427_row3_col3, #T_f2427_row3_col4, #T_f2427_row3_col5, #T_f2427_row3_col6, #T_f2427_row3_col7, #T_f2427_row4_col4, #T_f2427_row7_col0, #T_f2427_row7_col1 {\n",
       "  background-color: #006837;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2427_row2_col5 {\n",
       "  background-color: #fede89;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2427_row2_col6 {\n",
       "  background-color: #fa9857;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2427_row3_col0 {\n",
       "  background-color: #fffdbc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2427_row3_col1 {\n",
       "  background-color: #fdb163;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2427_row4_col0 {\n",
       "  background-color: #e6f59d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2427_row4_col1 {\n",
       "  background-color: #ed5f3c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2427_row4_col3 {\n",
       "  background-color: #cbe982;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2427_row4_col5 {\n",
       "  background-color: #96d268;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2427_row4_col6 {\n",
       "  background-color: #ddf191;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2427_row5_col0 {\n",
       "  background-color: #f5fbb2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2427_row5_col1 {\n",
       "  background-color: #f88950;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2427_row6_col0 {\n",
       "  background-color: #abdb6d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2427_row6_col1 {\n",
       "  background-color: #fee08b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2427_row6_col5 {\n",
       "  background-color: #fb9d59;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2427_row6_col6 {\n",
       "  background-color: #fee491;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2427_row8_col0 {\n",
       "  background-color: #f7fcb4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2427_row8_col1 {\n",
       "  background-color: #fdbb6c;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f2427_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >fit_time</th>\n",
       "      <th class=\"col_heading level0 col1\" >score_time</th>\n",
       "      <th class=\"col_heading level0 col2\" >test_accuracy</th>\n",
       "      <th class=\"col_heading level0 col3\" >test_precision</th>\n",
       "      <th class=\"col_heading level0 col4\" >test_recall</th>\n",
       "      <th class=\"col_heading level0 col5\" >test_f1</th>\n",
       "      <th class=\"col_heading level0 col6\" >test_f1_macro</th>\n",
       "      <th class=\"col_heading level0 col7\" >test_f1_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f2427_level0_row0\" class=\"row_heading level0 row0\" >5000</th>\n",
       "      <td id=\"T_f2427_row0_col0\" class=\"data row0 col0\" >0.006741</td>\n",
       "      <td id=\"T_f2427_row0_col1\" class=\"data row0 col1\" >0.009335</td>\n",
       "      <td id=\"T_f2427_row0_col2\" class=\"data row0 col2\" >0.887500</td>\n",
       "      <td id=\"T_f2427_row0_col3\" class=\"data row0 col3\" >0.868095</td>\n",
       "      <td id=\"T_f2427_row0_col4\" class=\"data row0 col4\" >0.980000</td>\n",
       "      <td id=\"T_f2427_row0_col5\" class=\"data row0 col5\" >0.917879</td>\n",
       "      <td id=\"T_f2427_row0_col6\" class=\"data row0 col6\" >0.867273</td>\n",
       "      <td id=\"T_f2427_row0_col7\" class=\"data row0 col7\" >0.887500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2427_level0_row1\" class=\"row_heading level0 row1\" >10000</th>\n",
       "      <td id=\"T_f2427_row1_col0\" class=\"data row1 col0\" >0.008804</td>\n",
       "      <td id=\"T_f2427_row1_col1\" class=\"data row1 col1\" >0.010193</td>\n",
       "      <td id=\"T_f2427_row1_col2\" class=\"data row1 col2\" >0.887500</td>\n",
       "      <td id=\"T_f2427_row1_col3\" class=\"data row1 col3\" >0.868095</td>\n",
       "      <td id=\"T_f2427_row1_col4\" class=\"data row1 col4\" >0.980000</td>\n",
       "      <td id=\"T_f2427_row1_col5\" class=\"data row1 col5\" >0.917879</td>\n",
       "      <td id=\"T_f2427_row1_col6\" class=\"data row1 col6\" >0.867273</td>\n",
       "      <td id=\"T_f2427_row1_col7\" class=\"data row1 col7\" >0.887500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2427_level0_row2\" class=\"row_heading level0 row2\" >15000</th>\n",
       "      <td id=\"T_f2427_row2_col0\" class=\"data row2 col0\" >0.009937</td>\n",
       "      <td id=\"T_f2427_row2_col1\" class=\"data row2 col1\" >0.009778</td>\n",
       "      <td id=\"T_f2427_row2_col2\" class=\"data row2 col2\" >0.875000</td>\n",
       "      <td id=\"T_f2427_row2_col3\" class=\"data row2 col3\" >0.847619</td>\n",
       "      <td id=\"T_f2427_row2_col4\" class=\"data row2 col4\" >1.000000</td>\n",
       "      <td id=\"T_f2427_row2_col5\" class=\"data row2 col5\" >0.913636</td>\n",
       "      <td id=\"T_f2427_row2_col6\" class=\"data row2 col6\" >0.841818</td>\n",
       "      <td id=\"T_f2427_row2_col7\" class=\"data row2 col7\" >0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2427_level0_row3\" class=\"row_heading level0 row3\" >17500</th>\n",
       "      <td id=\"T_f2427_row3_col0\" class=\"data row3 col0\" >0.010999</td>\n",
       "      <td id=\"T_f2427_row3_col1\" class=\"data row3 col1\" >0.010392</td>\n",
       "      <td id=\"T_f2427_row3_col2\" class=\"data row3 col2\" >0.900000</td>\n",
       "      <td id=\"T_f2427_row3_col3\" class=\"data row3 col3\" >0.876190</td>\n",
       "      <td id=\"T_f2427_row3_col4\" class=\"data row3 col4\" >1.000000</td>\n",
       "      <td id=\"T_f2427_row3_col5\" class=\"data row3 col5\" >0.930303</td>\n",
       "      <td id=\"T_f2427_row3_col6\" class=\"data row3 col6\" >0.875152</td>\n",
       "      <td id=\"T_f2427_row3_col7\" class=\"data row3 col7\" >0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2427_level0_row4\" class=\"row_heading level0 row4\" >20000</th>\n",
       "      <td id=\"T_f2427_row4_col0\" class=\"data row4 col0\" >0.011596</td>\n",
       "      <td id=\"T_f2427_row4_col1\" class=\"data row4 col1\" >0.009950</td>\n",
       "      <td id=\"T_f2427_row4_col2\" class=\"data row4 col2\" >0.887500</td>\n",
       "      <td id=\"T_f2427_row4_col3\" class=\"data row4 col3\" >0.864286</td>\n",
       "      <td id=\"T_f2427_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "      <td id=\"T_f2427_row4_col5\" class=\"data row4 col5\" >0.922727</td>\n",
       "      <td id=\"T_f2427_row4_col6\" class=\"data row4 col6\" >0.856364</td>\n",
       "      <td id=\"T_f2427_row4_col7\" class=\"data row4 col7\" >0.887500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2427_level0_row5\" class=\"row_heading level0 row5\" >22500</th>\n",
       "      <td id=\"T_f2427_row5_col0\" class=\"data row5 col0\" >0.011248</td>\n",
       "      <td id=\"T_f2427_row5_col1\" class=\"data row5 col1\" >0.010174</td>\n",
       "      <td id=\"T_f2427_row5_col2\" class=\"data row5 col2\" >0.862500</td>\n",
       "      <td id=\"T_f2427_row5_col3\" class=\"data row5 col3\" >0.844286</td>\n",
       "      <td id=\"T_f2427_row5_col4\" class=\"data row5 col4\" >0.980000</td>\n",
       "      <td id=\"T_f2427_row5_col5\" class=\"data row5 col5\" >0.902727</td>\n",
       "      <td id=\"T_f2427_row5_col6\" class=\"data row5 col6\" >0.829697</td>\n",
       "      <td id=\"T_f2427_row5_col7\" class=\"data row5 col7\" >0.862500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2427_level0_row6\" class=\"row_heading level0 row6\" >25000</th>\n",
       "      <td id=\"T_f2427_row6_col0\" class=\"data row6 col0\" >0.012680</td>\n",
       "      <td id=\"T_f2427_row6_col1\" class=\"data row6 col1\" >0.010711</td>\n",
       "      <td id=\"T_f2427_row6_col2\" class=\"data row6 col2\" >0.875000</td>\n",
       "      <td id=\"T_f2427_row6_col3\" class=\"data row6 col3\" >0.856190</td>\n",
       "      <td id=\"T_f2427_row6_col4\" class=\"data row6 col4\" >0.980000</td>\n",
       "      <td id=\"T_f2427_row6_col5\" class=\"data row6 col5\" >0.910303</td>\n",
       "      <td id=\"T_f2427_row6_col6\" class=\"data row6 col6\" >0.848485</td>\n",
       "      <td id=\"T_f2427_row6_col7\" class=\"data row6 col7\" >0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2427_level0_row7\" class=\"row_heading level0 row7\" >30000</th>\n",
       "      <td id=\"T_f2427_row7_col0\" class=\"data row7 col0\" >0.015340</td>\n",
       "      <td id=\"T_f2427_row7_col1\" class=\"data row7 col1\" >0.012773</td>\n",
       "      <td id=\"T_f2427_row7_col2\" class=\"data row7 col2\" >0.887500</td>\n",
       "      <td id=\"T_f2427_row7_col3\" class=\"data row7 col3\" >0.868095</td>\n",
       "      <td id=\"T_f2427_row7_col4\" class=\"data row7 col4\" >0.980000</td>\n",
       "      <td id=\"T_f2427_row7_col5\" class=\"data row7 col5\" >0.917879</td>\n",
       "      <td id=\"T_f2427_row7_col6\" class=\"data row7 col6\" >0.867273</td>\n",
       "      <td id=\"T_f2427_row7_col7\" class=\"data row7 col7\" >0.887500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2427_level0_row8\" class=\"row_heading level0 row8\" >35000</th>\n",
       "      <td id=\"T_f2427_row8_col0\" class=\"data row8 col0\" >0.011224</td>\n",
       "      <td id=\"T_f2427_row8_col1\" class=\"data row8 col1\" >0.010450</td>\n",
       "      <td id=\"T_f2427_row8_col2\" class=\"data row8 col2\" >0.887500</td>\n",
       "      <td id=\"T_f2427_row8_col3\" class=\"data row8 col3\" >0.868095</td>\n",
       "      <td id=\"T_f2427_row8_col4\" class=\"data row8 col4\" >0.980000</td>\n",
       "      <td id=\"T_f2427_row8_col5\" class=\"data row8 col5\" >0.917879</td>\n",
       "      <td id=\"T_f2427_row8_col6\" class=\"data row8 col6\" >0.867273</td>\n",
       "      <td id=\"T_f2427_row8_col7\" class=\"data row8 col7\" >0.887500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19eb63c51f0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_n2=[]\n",
    "matrix_n2= {}\n",
    "feat_n2 = [15000,16000,17000,18000,19000,20000,17500]\n",
    "for x in feat_n2:\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        encoding='utf-8',\n",
    "        preprocessor=pre_proc,\n",
    "        min_df=2, # Note this\n",
    "        max_df=0.8, # This, too\n",
    "        binary=False,\n",
    "        norm='l2',\n",
    "        use_idf=True, # And this\n",
    "        max_features=x)\n",
    "    vect_n.append(vectorizer)\n",
    "    matrix = vectorizer.fit_transform(training_books)\n",
    "    X_train_Z = StandardScaler(with_mean=False).fit_transform(matrix)\n",
    "    dict_key=str(x)\n",
    "    matrix_n2[dict_key] = X_train_Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2 = {} # Store cross-validation results in a dictionary\n",
    "for matrix2 in matrix_n2: \n",
    "    scores2[matrix2] = cross_validate( # perform cross-validation\n",
    "        MultinomialNB(), # classifier object\n",
    "        matrix_n2[matrix2], # feature matrix\n",
    "        y_train, # gold labels\n",
    "        cv=10, #number of folds\n",
    "        scoring=['accuracy','precision', 'recall', 'f1', 'f1_macro', 'f1_micro'] # scoring methods\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8875c_row0_col0 {\n",
       "  background-color: #fede89;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8875c_row0_col1 {\n",
       "  background-color: #57b65f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8875c_row0_col2, #T_8875c_row0_col3, #T_8875c_row0_col6, #T_8875c_row0_col7, #T_8875c_row1_col2, #T_8875c_row1_col4, #T_8875c_row1_col5, #T_8875c_row1_col7, #T_8875c_row2_col2, #T_8875c_row2_col4, #T_8875c_row2_col5, #T_8875c_row2_col7, #T_8875c_row3_col4, #T_8875c_row5_col1, #T_8875c_row6_col0 {\n",
       "  background-color: #a50026;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8875c_row0_col4, #T_8875c_row1_col1, #T_8875c_row2_col0, #T_8875c_row3_col3, #T_8875c_row4_col2, #T_8875c_row4_col3, #T_8875c_row4_col4, #T_8875c_row4_col5, #T_8875c_row4_col6, #T_8875c_row4_col7, #T_8875c_row5_col4, #T_8875c_row6_col2, #T_8875c_row6_col3, #T_8875c_row6_col4, #T_8875c_row6_col5, #T_8875c_row6_col6, #T_8875c_row6_col7 {\n",
       "  background-color: #006837;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8875c_row0_col5 {\n",
       "  background-color: #d93429;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8875c_row1_col0 {\n",
       "  background-color: #ee613e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8875c_row1_col3, #T_8875c_row2_col3, #T_8875c_row5_col3 {\n",
       "  background-color: #dff293;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8875c_row1_col6, #T_8875c_row2_col6 {\n",
       "  background-color: #c01a27;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8875c_row2_col1 {\n",
       "  background-color: #f98e52;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8875c_row3_col0 {\n",
       "  background-color: #feeda1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8875c_row3_col1 {\n",
       "  background-color: #a7d96b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8875c_row3_col2, #T_8875c_row3_col7, #T_8875c_row5_col2, #T_8875c_row5_col7 {\n",
       "  background-color: #fffebe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8875c_row3_col5 {\n",
       "  background-color: #fee18d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8875c_row3_col6 {\n",
       "  background-color: #cfeb85;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8875c_row4_col0 {\n",
       "  background-color: #4bb05c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8875c_row4_col1 {\n",
       "  background-color: #dc3b2c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8875c_row5_col0 {\n",
       "  background-color: #15904c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8875c_row5_col5 {\n",
       "  background-color: #daf08d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8875c_row5_col6 {\n",
       "  background-color: #feeb9d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8875c_row6_col1 {\n",
       "  background-color: #ebf7a3;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8875c_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >fit_time</th>\n",
       "      <th class=\"col_heading level0 col1\" >score_time</th>\n",
       "      <th class=\"col_heading level0 col2\" >test_accuracy</th>\n",
       "      <th class=\"col_heading level0 col3\" >test_precision</th>\n",
       "      <th class=\"col_heading level0 col4\" >test_recall</th>\n",
       "      <th class=\"col_heading level0 col5\" >test_f1</th>\n",
       "      <th class=\"col_heading level0 col6\" >test_f1_macro</th>\n",
       "      <th class=\"col_heading level0 col7\" >test_f1_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8875c_level0_row0\" class=\"row_heading level0 row0\" >15000</th>\n",
       "      <td id=\"T_8875c_row0_col0\" class=\"data row0 col0\" >0.009940</td>\n",
       "      <td id=\"T_8875c_row0_col1\" class=\"data row0 col1\" >0.009580</td>\n",
       "      <td id=\"T_8875c_row0_col2\" class=\"data row0 col2\" >0.875000</td>\n",
       "      <td id=\"T_8875c_row0_col3\" class=\"data row0 col3\" >0.847619</td>\n",
       "      <td id=\"T_8875c_row0_col4\" class=\"data row0 col4\" >1.000000</td>\n",
       "      <td id=\"T_8875c_row0_col5\" class=\"data row0 col5\" >0.913636</td>\n",
       "      <td id=\"T_8875c_row0_col6\" class=\"data row0 col6\" >0.841818</td>\n",
       "      <td id=\"T_8875c_row0_col7\" class=\"data row0 col7\" >0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8875c_level0_row1\" class=\"row_heading level0 row1\" >16000</th>\n",
       "      <td id=\"T_8875c_row1_col0\" class=\"data row1 col0\" >0.009666</td>\n",
       "      <td id=\"T_8875c_row1_col1\" class=\"data row1 col1\" >0.009706</td>\n",
       "      <td id=\"T_8875c_row1_col2\" class=\"data row1 col2\" >0.875000</td>\n",
       "      <td id=\"T_8875c_row1_col3\" class=\"data row1 col3\" >0.864286</td>\n",
       "      <td id=\"T_8875c_row1_col4\" class=\"data row1 col4\" >0.980000</td>\n",
       "      <td id=\"T_8875c_row1_col5\" class=\"data row1 col5\" >0.911616</td>\n",
       "      <td id=\"T_8875c_row1_col6\" class=\"data row1 col6\" >0.843665</td>\n",
       "      <td id=\"T_8875c_row1_col7\" class=\"data row1 col7\" >0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8875c_level0_row2\" class=\"row_heading level0 row2\" >17000</th>\n",
       "      <td id=\"T_8875c_row2_col0\" class=\"data row2 col0\" >0.010716</td>\n",
       "      <td id=\"T_8875c_row2_col1\" class=\"data row2 col1\" >0.009188</td>\n",
       "      <td id=\"T_8875c_row2_col2\" class=\"data row2 col2\" >0.875000</td>\n",
       "      <td id=\"T_8875c_row2_col3\" class=\"data row2 col3\" >0.864286</td>\n",
       "      <td id=\"T_8875c_row2_col4\" class=\"data row2 col4\" >0.980000</td>\n",
       "      <td id=\"T_8875c_row2_col5\" class=\"data row2 col5\" >0.911616</td>\n",
       "      <td id=\"T_8875c_row2_col6\" class=\"data row2 col6\" >0.843665</td>\n",
       "      <td id=\"T_8875c_row2_col7\" class=\"data row2 col7\" >0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8875c_level0_row3\" class=\"row_heading level0 row3\" >18000</th>\n",
       "      <td id=\"T_8875c_row3_col0\" class=\"data row3 col0\" >0.010003</td>\n",
       "      <td id=\"T_8875c_row3_col1\" class=\"data row3 col1\" >0.009495</td>\n",
       "      <td id=\"T_8875c_row3_col2\" class=\"data row3 col2\" >0.887500</td>\n",
       "      <td id=\"T_8875c_row3_col3\" class=\"data row3 col3\" >0.876190</td>\n",
       "      <td id=\"T_8875c_row3_col4\" class=\"data row3 col4\" >0.980000</td>\n",
       "      <td id=\"T_8875c_row3_col5\" class=\"data row3 col5\" >0.919192</td>\n",
       "      <td id=\"T_8875c_row3_col6\" class=\"data row3 col6\" >0.862453</td>\n",
       "      <td id=\"T_8875c_row3_col7\" class=\"data row3 col7\" >0.887500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8875c_level0_row4\" class=\"row_heading level0 row4\" >19000</th>\n",
       "      <td id=\"T_8875c_row4_col0\" class=\"data row4 col0\" >0.010505</td>\n",
       "      <td id=\"T_8875c_row4_col1\" class=\"data row4 col1\" >0.009096</td>\n",
       "      <td id=\"T_8875c_row4_col2\" class=\"data row4 col2\" >0.900000</td>\n",
       "      <td id=\"T_8875c_row4_col3\" class=\"data row4 col3\" >0.876190</td>\n",
       "      <td id=\"T_8875c_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "      <td id=\"T_8875c_row4_col5\" class=\"data row4 col5\" >0.930303</td>\n",
       "      <td id=\"T_8875c_row4_col6\" class=\"data row4 col6\" >0.875152</td>\n",
       "      <td id=\"T_8875c_row4_col7\" class=\"data row4 col7\" >0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8875c_level0_row5\" class=\"row_heading level0 row5\" >20000</th>\n",
       "      <td id=\"T_8875c_row5_col0\" class=\"data row5 col0\" >0.010608</td>\n",
       "      <td id=\"T_8875c_row5_col1\" class=\"data row5 col1\" >0.009014</td>\n",
       "      <td id=\"T_8875c_row5_col2\" class=\"data row5 col2\" >0.887500</td>\n",
       "      <td id=\"T_8875c_row5_col3\" class=\"data row5 col3\" >0.864286</td>\n",
       "      <td id=\"T_8875c_row5_col4\" class=\"data row5 col4\" >1.000000</td>\n",
       "      <td id=\"T_8875c_row5_col5\" class=\"data row5 col5\" >0.922727</td>\n",
       "      <td id=\"T_8875c_row5_col6\" class=\"data row5 col6\" >0.856364</td>\n",
       "      <td id=\"T_8875c_row5_col7\" class=\"data row5 col7\" >0.887500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8875c_level0_row6\" class=\"row_heading level0 row6\" >17500</th>\n",
       "      <td id=\"T_8875c_row6_col0\" class=\"data row6 col0\" >0.009432</td>\n",
       "      <td id=\"T_8875c_row6_col1\" class=\"data row6 col1\" >0.009396</td>\n",
       "      <td id=\"T_8875c_row6_col2\" class=\"data row6 col2\" >0.900000</td>\n",
       "      <td id=\"T_8875c_row6_col3\" class=\"data row6 col3\" >0.876190</td>\n",
       "      <td id=\"T_8875c_row6_col4\" class=\"data row6 col4\" >1.000000</td>\n",
       "      <td id=\"T_8875c_row6_col5\" class=\"data row6 col5\" >0.930303</td>\n",
       "      <td id=\"T_8875c_row6_col6\" class=\"data row6 col6\" >0.875152</td>\n",
       "      <td id=\"T_8875c_row6_col7\" class=\"data row6 col7\" >0.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19ea861ba90>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_scores(scores2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5564c_row0_col0 {\n",
       "  background-color: #138c4a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5564c_row0_col1 {\n",
       "  background-color: #1e9a51;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5564c_row0_col2, #T_5564c_row0_col3, #T_5564c_row0_col4, #T_5564c_row0_col5, #T_5564c_row0_col6, #T_5564c_row0_col7, #T_5564c_row1_col2, #T_5564c_row1_col3, #T_5564c_row1_col4, #T_5564c_row1_col5, #T_5564c_row1_col6, #T_5564c_row1_col7, #T_5564c_row2_col1, #T_5564c_row2_col2, #T_5564c_row2_col3, #T_5564c_row2_col4, #T_5564c_row2_col5, #T_5564c_row2_col6, #T_5564c_row2_col7, #T_5564c_row3_col0, #T_5564c_row3_col2, #T_5564c_row3_col3, #T_5564c_row3_col4, #T_5564c_row3_col5, #T_5564c_row3_col6, #T_5564c_row3_col7, #T_5564c_row4_col2, #T_5564c_row4_col3, #T_5564c_row4_col4, #T_5564c_row4_col5, #T_5564c_row4_col6, #T_5564c_row4_col7 {\n",
       "  background-color: #a50026;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5564c_row1_col0 {\n",
       "  background-color: #33a456;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5564c_row1_col1, #T_5564c_row2_col0 {\n",
       "  background-color: #006837;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5564c_row3_col1 {\n",
       "  background-color: #148e4b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5564c_row4_col0 {\n",
       "  background-color: #17934e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5564c_row4_col1 {\n",
       "  background-color: #d1ec86;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5564c_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >fit_time</th>\n",
       "      <th class=\"col_heading level0 col1\" >score_time</th>\n",
       "      <th class=\"col_heading level0 col2\" >test_accuracy</th>\n",
       "      <th class=\"col_heading level0 col3\" >test_precision</th>\n",
       "      <th class=\"col_heading level0 col4\" >test_recall</th>\n",
       "      <th class=\"col_heading level0 col5\" >test_f1</th>\n",
       "      <th class=\"col_heading level0 col6\" >test_f1_macro</th>\n",
       "      <th class=\"col_heading level0 col7\" >test_f1_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5564c_level0_row0\" class=\"row_heading level0 row0\" >log1</th>\n",
       "      <td id=\"T_5564c_row0_col0\" class=\"data row0 col0\" >0.447972</td>\n",
       "      <td id=\"T_5564c_row0_col1\" class=\"data row0 col1\" >0.011594</td>\n",
       "      <td id=\"T_5564c_row0_col2\" class=\"data row0 col2\" >0.800000</td>\n",
       "      <td id=\"T_5564c_row0_col3\" class=\"data row0 col3\" >0.786310</td>\n",
       "      <td id=\"T_5564c_row0_col4\" class=\"data row0 col4\" >0.983333</td>\n",
       "      <td id=\"T_5564c_row0_col5\" class=\"data row0 col5\" >0.866317</td>\n",
       "      <td id=\"T_5564c_row0_col6\" class=\"data row0 col6\" >0.728159</td>\n",
       "      <td id=\"T_5564c_row0_col7\" class=\"data row0 col7\" >0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5564c_level0_row1\" class=\"row_heading level0 row1\" >log2</th>\n",
       "      <td id=\"T_5564c_row1_col0\" class=\"data row1 col0\" >0.446253</td>\n",
       "      <td id=\"T_5564c_row1_col1\" class=\"data row1 col1\" >0.011721</td>\n",
       "      <td id=\"T_5564c_row1_col2\" class=\"data row1 col2\" >0.800000</td>\n",
       "      <td id=\"T_5564c_row1_col3\" class=\"data row1 col3\" >0.786310</td>\n",
       "      <td id=\"T_5564c_row1_col4\" class=\"data row1 col4\" >0.983333</td>\n",
       "      <td id=\"T_5564c_row1_col5\" class=\"data row1 col5\" >0.866317</td>\n",
       "      <td id=\"T_5564c_row1_col6\" class=\"data row1 col6\" >0.728159</td>\n",
       "      <td id=\"T_5564c_row1_col7\" class=\"data row1 col7\" >0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5564c_level0_row2\" class=\"row_heading level0 row2\" >log3</th>\n",
       "      <td id=\"T_5564c_row2_col0\" class=\"data row2 col0\" >0.450153</td>\n",
       "      <td id=\"T_5564c_row2_col1\" class=\"data row2 col1\" >0.010538</td>\n",
       "      <td id=\"T_5564c_row2_col2\" class=\"data row2 col2\" >0.800000</td>\n",
       "      <td id=\"T_5564c_row2_col3\" class=\"data row2 col3\" >0.786310</td>\n",
       "      <td id=\"T_5564c_row2_col4\" class=\"data row2 col4\" >0.983333</td>\n",
       "      <td id=\"T_5564c_row2_col5\" class=\"data row2 col5\" >0.866317</td>\n",
       "      <td id=\"T_5564c_row2_col6\" class=\"data row2 col6\" >0.728159</td>\n",
       "      <td id=\"T_5564c_row2_col7\" class=\"data row2 col7\" >0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5564c_level0_row3\" class=\"row_heading level0 row3\" >log4</th>\n",
       "      <td id=\"T_5564c_row3_col0\" class=\"data row3 col0\" >0.421565</td>\n",
       "      <td id=\"T_5564c_row3_col1\" class=\"data row3 col1\" >0.011627</td>\n",
       "      <td id=\"T_5564c_row3_col2\" class=\"data row3 col2\" >0.800000</td>\n",
       "      <td id=\"T_5564c_row3_col3\" class=\"data row3 col3\" >0.786310</td>\n",
       "      <td id=\"T_5564c_row3_col4\" class=\"data row3 col4\" >0.983333</td>\n",
       "      <td id=\"T_5564c_row3_col5\" class=\"data row3 col5\" >0.866317</td>\n",
       "      <td id=\"T_5564c_row3_col6\" class=\"data row3 col6\" >0.728159</td>\n",
       "      <td id=\"T_5564c_row3_col7\" class=\"data row3 col7\" >0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5564c_level0_row4\" class=\"row_heading level0 row4\" >log5</th>\n",
       "      <td id=\"T_5564c_row4_col0\" class=\"data row4 col0\" >0.447583</td>\n",
       "      <td id=\"T_5564c_row4_col1\" class=\"data row4 col1\" >0.011263</td>\n",
       "      <td id=\"T_5564c_row4_col2\" class=\"data row4 col2\" >0.800000</td>\n",
       "      <td id=\"T_5564c_row4_col3\" class=\"data row4 col3\" >0.786310</td>\n",
       "      <td id=\"T_5564c_row4_col4\" class=\"data row4 col4\" >0.983333</td>\n",
       "      <td id=\"T_5564c_row4_col5\" class=\"data row4 col5\" >0.866317</td>\n",
       "      <td id=\"T_5564c_row4_col6\" class=\"data row4 col6\" >0.728159</td>\n",
       "      <td id=\"T_5564c_row4_col7\" class=\"data row4 col7\" >0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19ea2e50640>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit log reg classifier\n",
    "log_classifiers = {\n",
    "    'log1':LogisticRegression(),\n",
    "    'log2':LogisticRegression(max_iter = 1000),\n",
    "    'log3':LogisticRegression(max_iter = 5000),\n",
    "    'log4':LogisticRegression(max_iter = 10000),\n",
    "    'log5':LogisticRegression(max_iter = 50000)\n",
    "}\n",
    "\n",
    "scores = {} # Store cross-validation results in a dictionary\n",
    "for classifier in log_classifiers: \n",
    "    scores[classifier] = cross_validate( # perform cross-validation\n",
    "        log_classifiers[classifier], # classifier object\n",
    "        X_train_Z, # feature matrix\n",
    "        y_train, # gold labels\n",
    "        cv=10, #number of folds\n",
    "        scoring=['accuracy','precision', 'recall', 'f1', 'f1_macro', 'f1_micro'] # scoring methods\n",
    "    )\n",
    "       \n",
    "compare_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 5000)\n",
      "(80, 10000)\n",
      "(80, 15000)\n",
      "(80, 17500)\n",
      "(80, 20000)\n",
      "(80, 22500)\n",
      "(80, 25000)\n",
      "(80, 30000)\n",
      "(80, 30376)\n"
     ]
    }
   ],
   "source": [
    "scores = {} # Store cross-validation results in a dictionary\n",
    "for matrix in matrix_n: \n",
    "    print(matrix_n[matrix].shape)\n",
    "    scores[matrix] = cross_validate( # perform cross-validation\n",
    "        LogisticRegression(), # classifier object\n",
    "        matrix_n[matrix], # feature matrix\n",
    "        y_train, # gold labels\n",
    "        cv=10, #number of folds\n",
    "        scoring=['accuracy','precision', 'recall', 'f1', 'f1_macro', 'f1_micro'] # scoring methods\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ccb20_row0_col0, #T_ccb20_row0_col1, #T_ccb20_row1_col4, #T_ccb20_row7_col2, #T_ccb20_row7_col3, #T_ccb20_row7_col5, #T_ccb20_row7_col6, #T_ccb20_row7_col7, #T_ccb20_row8_col2, #T_ccb20_row8_col3, #T_ccb20_row8_col5, #T_ccb20_row8_col6, #T_ccb20_row8_col7 {\n",
       "  background-color: #a50026;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ccb20_row0_col2, #T_ccb20_row0_col3, #T_ccb20_row0_col5, #T_ccb20_row0_col6, #T_ccb20_row0_col7, #T_ccb20_row5_col1, #T_ccb20_row5_col4, #T_ccb20_row6_col4, #T_ccb20_row7_col4, #T_ccb20_row8_col0, #T_ccb20_row8_col4 {\n",
       "  background-color: #006837;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ccb20_row0_col4 {\n",
       "  background-color: #fff1a8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccb20_row1_col0 {\n",
       "  background-color: #f99153;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccb20_row1_col1 {\n",
       "  background-color: #e0f295;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccb20_row1_col2, #T_ccb20_row1_col7, #T_ccb20_row2_col2, #T_ccb20_row2_col7 {\n",
       "  background-color: #fee999;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccb20_row1_col3 {\n",
       "  background-color: #f1f9ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccb20_row1_col5 {\n",
       "  background-color: #fdaf62;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccb20_row1_col6 {\n",
       "  background-color: #ddf191;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccb20_row2_col0 {\n",
       "  background-color: #fed884;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccb20_row2_col1 {\n",
       "  background-color: #c1e57b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccb20_row2_col3 {\n",
       "  background-color: #fff7b2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccb20_row2_col4, #T_ccb20_row3_col4, #T_ccb20_row4_col4 {\n",
       "  background-color: #eef8a8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccb20_row2_col5 {\n",
       "  background-color: #fede89;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccb20_row2_col6 {\n",
       "  background-color: #fffcba;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccb20_row3_col0 {\n",
       "  background-color: #feeb9d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccb20_row3_col1 {\n",
       "  background-color: #fdb96a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccb20_row3_col2, #T_ccb20_row3_col7, #T_ccb20_row5_col2, #T_ccb20_row5_col7, #T_ccb20_row6_col1 {\n",
       "  background-color: #fca55d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccb20_row3_col3 {\n",
       "  background-color: #fdc171;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccb20_row3_col5, #T_ccb20_row4_col3, #T_ccb20_row5_col3 {\n",
       "  background-color: #f7844e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ccb20_row3_col6 {\n",
       "  background-color: #fed27f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccb20_row4_col0 {\n",
       "  background-color: #fffebe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccb20_row4_col1 {\n",
       "  background-color: #f67a49;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ccb20_row4_col2, #T_ccb20_row4_col7, #T_ccb20_row6_col2, #T_ccb20_row6_col7 {\n",
       "  background-color: #e34933;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ccb20_row4_col5, #T_ccb20_row6_col3 {\n",
       "  background-color: #d83128;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ccb20_row4_col6 {\n",
       "  background-color: #f46d43;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ccb20_row5_col0 {\n",
       "  background-color: #d1ec86;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccb20_row5_col5 {\n",
       "  background-color: #fcaa5f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccb20_row5_col6 {\n",
       "  background-color: #fca85e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccb20_row6_col0 {\n",
       "  background-color: #96d268;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccb20_row6_col5 {\n",
       "  background-color: #e14430;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ccb20_row6_col6 {\n",
       "  background-color: #ec5c3b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ccb20_row7_col0 {\n",
       "  background-color: #026c39;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ccb20_row7_col1 {\n",
       "  background-color: #a9da6c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ccb20_row8_col1 {\n",
       "  background-color: #91d068;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ccb20_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >fit_time</th>\n",
       "      <th class=\"col_heading level0 col1\" >score_time</th>\n",
       "      <th class=\"col_heading level0 col2\" >test_accuracy</th>\n",
       "      <th class=\"col_heading level0 col3\" >test_precision</th>\n",
       "      <th class=\"col_heading level0 col4\" >test_recall</th>\n",
       "      <th class=\"col_heading level0 col5\" >test_f1</th>\n",
       "      <th class=\"col_heading level0 col6\" >test_f1_macro</th>\n",
       "      <th class=\"col_heading level0 col7\" >test_f1_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ccb20_level0_row0\" class=\"row_heading level0 row0\" >5000</th>\n",
       "      <td id=\"T_ccb20_row0_col0\" class=\"data row0 col0\" >0.181777</td>\n",
       "      <td id=\"T_ccb20_row0_col1\" class=\"data row0 col1\" >0.009573</td>\n",
       "      <td id=\"T_ccb20_row0_col2\" class=\"data row0 col2\" >0.862500</td>\n",
       "      <td id=\"T_ccb20_row0_col3\" class=\"data row0 col3\" >0.844286</td>\n",
       "      <td id=\"T_ccb20_row0_col4\" class=\"data row0 col4\" >0.980000</td>\n",
       "      <td id=\"T_ccb20_row0_col5\" class=\"data row0 col5\" >0.902727</td>\n",
       "      <td id=\"T_ccb20_row0_col6\" class=\"data row0 col6\" >0.829697</td>\n",
       "      <td id=\"T_ccb20_row0_col7\" class=\"data row0 col7\" >0.862500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccb20_level0_row1\" class=\"row_heading level0 row1\" >10000</th>\n",
       "      <td id=\"T_ccb20_row1_col0\" class=\"data row1 col0\" >0.332523</td>\n",
       "      <td id=\"T_ccb20_row1_col1\" class=\"data row1 col1\" >0.010715</td>\n",
       "      <td id=\"T_ccb20_row1_col2\" class=\"data row1 col2\" >0.812500</td>\n",
       "      <td id=\"T_ccb20_row1_col3\" class=\"data row1 col3\" >0.803810</td>\n",
       "      <td id=\"T_ccb20_row1_col4\" class=\"data row1 col4\" >0.963333</td>\n",
       "      <td id=\"T_ccb20_row1_col5\" class=\"data row1 col5\" >0.869394</td>\n",
       "      <td id=\"T_ccb20_row1_col6\" class=\"data row1 col6\" >0.763030</td>\n",
       "      <td id=\"T_ccb20_row1_col7\" class=\"data row1 col7\" >0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccb20_level0_row2\" class=\"row_heading level0 row2\" >15000</th>\n",
       "      <td id=\"T_ccb20_row2_col0\" class=\"data row2 col0\" >0.408429</td>\n",
       "      <td id=\"T_ccb20_row2_col1\" class=\"data row2 col1\" >0.010847</td>\n",
       "      <td id=\"T_ccb20_row2_col2\" class=\"data row2 col2\" >0.812500</td>\n",
       "      <td id=\"T_ccb20_row2_col3\" class=\"data row2 col3\" >0.798214</td>\n",
       "      <td id=\"T_ccb20_row2_col4\" class=\"data row2 col4\" >0.983333</td>\n",
       "      <td id=\"T_ccb20_row2_col5\" class=\"data row2 col5\" >0.873893</td>\n",
       "      <td id=\"T_ccb20_row2_col6\" class=\"data row2 col6\" >0.746946</td>\n",
       "      <td id=\"T_ccb20_row2_col7\" class=\"data row2 col7\" >0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccb20_level0_row3\" class=\"row_heading level0 row3\" >17500</th>\n",
       "      <td id=\"T_ccb20_row3_col0\" class=\"data row3 col0\" >0.436322</td>\n",
       "      <td id=\"T_ccb20_row3_col1\" class=\"data row3 col1\" >0.010205</td>\n",
       "      <td id=\"T_ccb20_row3_col2\" class=\"data row3 col2\" >0.800000</td>\n",
       "      <td id=\"T_ccb20_row3_col3\" class=\"data row3 col3\" >0.786310</td>\n",
       "      <td id=\"T_ccb20_row3_col4\" class=\"data row3 col4\" >0.983333</td>\n",
       "      <td id=\"T_ccb20_row3_col5\" class=\"data row3 col5\" >0.866317</td>\n",
       "      <td id=\"T_ccb20_row3_col6\" class=\"data row3 col6\" >0.728159</td>\n",
       "      <td id=\"T_ccb20_row3_col7\" class=\"data row3 col7\" >0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccb20_level0_row4\" class=\"row_heading level0 row4\" >20000</th>\n",
       "      <td id=\"T_ccb20_row4_col0\" class=\"data row4 col0\" >0.474196</td>\n",
       "      <td id=\"T_ccb20_row4_col1\" class=\"data row4 col1\" >0.010005</td>\n",
       "      <td id=\"T_ccb20_row4_col2\" class=\"data row4 col2\" >0.787500</td>\n",
       "      <td id=\"T_ccb20_row4_col3\" class=\"data row4 col3\" >0.777381</td>\n",
       "      <td id=\"T_ccb20_row4_col4\" class=\"data row4 col4\" >0.983333</td>\n",
       "      <td id=\"T_ccb20_row4_col5\" class=\"data row4 col5\" >0.859907</td>\n",
       "      <td id=\"T_ccb20_row4_col6\" class=\"data row4 col6\" >0.699953</td>\n",
       "      <td id=\"T_ccb20_row4_col7\" class=\"data row4 col7\" >0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccb20_level0_row5\" class=\"row_heading level0 row5\" >22500</th>\n",
       "      <td id=\"T_ccb20_row5_col0\" class=\"data row5 col0\" >0.541965</td>\n",
       "      <td id=\"T_ccb20_row5_col1\" class=\"data row5 col1\" >0.011539</td>\n",
       "      <td id=\"T_ccb20_row5_col2\" class=\"data row5 col2\" >0.800000</td>\n",
       "      <td id=\"T_ccb20_row5_col3\" class=\"data row5 col3\" >0.777381</td>\n",
       "      <td id=\"T_ccb20_row5_col4\" class=\"data row5 col4\" >1.000000</td>\n",
       "      <td id=\"T_ccb20_row5_col5\" class=\"data row5 col5\" >0.868998</td>\n",
       "      <td id=\"T_ccb20_row5_col6\" class=\"data row5 col6\" >0.714499</td>\n",
       "      <td id=\"T_ccb20_row5_col7\" class=\"data row5 col7\" >0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccb20_level0_row6\" class=\"row_heading level0 row6\" >25000</th>\n",
       "      <td id=\"T_ccb20_row6_col0\" class=\"data row6 col0\" >0.606185</td>\n",
       "      <td id=\"T_ccb20_row6_col1\" class=\"data row6 col1\" >0.010137</td>\n",
       "      <td id=\"T_ccb20_row6_col2\" class=\"data row6 col2\" >0.787500</td>\n",
       "      <td id=\"T_ccb20_row6_col3\" class=\"data row6 col3\" >0.765476</td>\n",
       "      <td id=\"T_ccb20_row6_col4\" class=\"data row6 col4\" >1.000000</td>\n",
       "      <td id=\"T_ccb20_row6_col5\" class=\"data row6 col5\" >0.861422</td>\n",
       "      <td id=\"T_ccb20_row6_col6\" class=\"data row6 col6\" >0.695711</td>\n",
       "      <td id=\"T_ccb20_row6_col7\" class=\"data row6 col7\" >0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccb20_level0_row7\" class=\"row_heading level0 row7\" >30000</th>\n",
       "      <td id=\"T_ccb20_row7_col0\" class=\"data row7 col0\" >0.762614</td>\n",
       "      <td id=\"T_ccb20_row7_col1\" class=\"data row7 col1\" >0.010939</td>\n",
       "      <td id=\"T_ccb20_row7_col2\" class=\"data row7 col2\" >0.775000</td>\n",
       "      <td id=\"T_ccb20_row7_col3\" class=\"data row7 col3\" >0.756548</td>\n",
       "      <td id=\"T_ccb20_row7_col4\" class=\"data row7 col4\" >1.000000</td>\n",
       "      <td id=\"T_ccb20_row7_col5\" class=\"data row7 col5\" >0.855012</td>\n",
       "      <td id=\"T_ccb20_row7_col6\" class=\"data row7 col6\" >0.667506</td>\n",
       "      <td id=\"T_ccb20_row7_col7\" class=\"data row7 col7\" >0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ccb20_level0_row8\" class=\"row_heading level0 row8\" >35000</th>\n",
       "      <td id=\"T_ccb20_row8_col0\" class=\"data row8 col0\" >0.768601</td>\n",
       "      <td id=\"T_ccb20_row8_col1\" class=\"data row8 col1\" >0.011013</td>\n",
       "      <td id=\"T_ccb20_row8_col2\" class=\"data row8 col2\" >0.775000</td>\n",
       "      <td id=\"T_ccb20_row8_col3\" class=\"data row8 col3\" >0.756548</td>\n",
       "      <td id=\"T_ccb20_row8_col4\" class=\"data row8 col4\" >1.000000</td>\n",
       "      <td id=\"T_ccb20_row8_col5\" class=\"data row8 col5\" >0.855012</td>\n",
       "      <td id=\"T_ccb20_row8_col6\" class=\"data row8 col6\" >0.667506</td>\n",
       "      <td id=\"T_ccb20_row8_col7\" class=\"data row8 col7\" >0.775000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19ea860cbe0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## IV. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most important words horror books:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['content', 'reality', 'closer', 'flesh', 'yield', 'choice',\n",
       "       'attend', 'occur', 'struggled', 'whence', 'music', 'tender',\n",
       "       'storm', 'solemn', 'mass', 'distress', 'dreaming', 'kissed',\n",
       "       'flow', 'equal', 'trembled', 'gladly', 'wandering', 'travel',\n",
       "       'reasonable', 'strongly', 'endless', 'glory', 'motion',\n",
       "       'exhausted', 'provided', 'breathing', 'suffer', 'changes',\n",
       "       'contrast', 'sleeping', 'composed', 'confusion', 'encourage',\n",
       "       'considering', 'strain', 'wave', 'dreams', 'justified', 'animal',\n",
       "       'tortured', 'branches', 'dignity', 'turns', 'treated'],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The most important words detective books:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['marry', 'morrow', 'suspicions', 'famous', 'aroused', 'suspicious',\n",
       "       'warn', 'valuable', 'stolen', 'smoking', 'clue', 'profession',\n",
       "       'conceal', 'arrested', 'hunting', 'interests', 'advised',\n",
       "       'reasonable', 'impatiently', 'finds', 'objection', 'tragedy',\n",
       "       'prefer', 'liberty', 'exclamation', 'picking', 'begged', 'mud',\n",
       "       'visitors', 'tells', 'bending', 'absurd', 'gets', 'card',\n",
       "       'considering', 'propose', 'disappearance', 'lunch', 'crushed',\n",
       "       'consulted', 'investigation', 'gesture', 'employ', 'informed',\n",
       "       'appreciate', 'cigar', 'detective', 'blame', 'replaced',\n",
       "       'reputation'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#source: https://stackoverflow.com/questions/50526898/how-to-get-feature-importance-in-naive-bayes\n",
    "feat_impNB=MultinomialNB()\n",
    "s=feat_impNB.fit(matrix_n2['17500'],y_train)\n",
    "\n",
    "neg_class_prob_sorted = feat_impNB.feature_log_prob_[0, :].argsort()[::-1]\n",
    "pos_class_prob_sorted = feat_impNB.feature_log_prob_[1, :].argsort()[::-1]\n",
    "\n",
    "\n",
    "print(\"The most important words horror books:\\n\")\n",
    "display(np.take(vectorizer.get_feature_names_out(), neg_class_prob_sorted[:50]))\n",
    "print(\"\\nThe most important words detective books:\\n\")\n",
    "display(np.take(vectorizer.get_feature_names_out(), pos_class_prob_sorted[:50])) #??? detective=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Testing/Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "        encoding='utf-8',\n",
    "        preprocessor=pre_proc,\n",
    "        min_df=2, # Note this\n",
    "        max_df=0.8, # This, too\n",
    "        binary=False,\n",
    "        norm='l2',\n",
    "        use_idf=True, # And this\n",
    "        max_features=17500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer.fit_transform(testing_books)\n",
    "y_test = MultinomialNB().fit(matrix_n['17500'], y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing books predicted Detective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['A Round Dozen', 'A Sicillian Romance',\n",
       "       'Adele Doring at Boarding-School', 'Agnes Grey',\n",
       "       'An Old-Fashioned Girl', 'Anna Karenina', 'Don Quixote', 'Emma',\n",
       "       'Flatland', 'Key Out of Time',\n",
       "       \"Little Men: Life at Plumfield With Jo's Boys\", 'Little Women',\n",
       "       'Mansfield Park', 'Mathilda', 'Micah Clarke', 'Middlemarch',\n",
       "       'Mizora: A Prophecy', 'Moods', 'Mr. Standfast', 'Night and Day',\n",
       "       \"Nobody's Girl\", 'Our Mutual Friend', 'Persuasion', 'Plague Ship',\n",
       "       'Pride and Prejudice', 'Rainbow Valley', 'Sense and Sensibility',\n",
       "       'Sense and Sensibility', 'Shirley', 'Silas Marner', 'Star Hunter',\n",
       "       'Star of India', 'Storm over Warlock', 'Summer',\n",
       "       'The Age of Innocence', 'The Beautiful and Damned', 'The Bell Jar',\n",
       "       'The Best Made Plans', 'The Betrothed', 'The Colors of Space',\n",
       "       'The Defiant Agents', 'The Disturbing Charm',\n",
       "       'The Enchanted April', 'The Fall Of The Grand Sarrasin',\n",
       "       'The Four Corners', 'The Garden Party, and Other Stories',\n",
       "       'The Great Gatsby', \"The King of Elfland's Daughter\",\n",
       "       'The Last Man', 'The Lighthouse', 'The Lost Kafoozalum',\n",
       "       'The Moon and Sixpence', 'The Narrative of Sojourner Truth',\n",
       "       'The Picture of Dorian Gray', 'The Planet Savers',\n",
       "       'The Scottish Chiefs', 'The Song of the Lark', 'The Story Girl',\n",
       "       'The Strange Visitation', 'The Time Traders', 'The Voyage Out',\n",
       "       'The Wonderful Wizard of Oz', 'The Youngest Girl in the School',\n",
       "       'This Side of Paradise', 'To Kill A Mockingbird',\n",
       "       'Twenty Thousand Leagues Under the Sea', \"Uncle Tom's Cabin\",\n",
       "       'Voodoo Planet'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data['y_pred']=y_test\n",
    "print(len(testing_data[testing_data['y_pred']==1].title.values))\n",
    "testing_data[testing_data['y_pred']==1].title.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing books predicted Horror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Anne of Green Gables', 'Black Amazon of Mars',\n",
       "       'Chaplet Of Pearls', 'House of Mirth', 'The Deluge',\n",
       "       'The Door Through Space',\n",
       "       'The Importance of Being Earnest: A Trivial Comedy for Serious People by Oscar Wilde',\n",
       "       'The Lances of Lynwood', 'The Luckiest Girl in the School',\n",
       "       'The Mill On The Floss'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(testing_data[testing_data['y_pred']==0].title.values))\n",
    "testing_data[testing_data['y_pred']==0].title.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction of true detective novels in the training dataset: 0.6375\n",
      "fraction of novels of testing dataset predicted detective: 0.8717948717948718\n"
     ]
    }
   ],
   "source": [
    "print(\"fraction of true detective novels in the training dataset:\", len(training_data[training_data['detective']==True])/(len(training_books)))\n",
    "print(\"fraction of novels of testing dataset predicted detective:\", len(testing_data[testing_data['y_pred']==1].title.values)/len(testing_books))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_books=training_books+testing_books\n",
    "vis=vectorizer.fit_transform(all_books)\n",
    "labels=np.hstack((y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>check_1</th>\n",
       "      <th>check_2</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>author1_surname</th>\n",
       "      <th>author1_givenname</th>\n",
       "      <th>author2_surname</th>\n",
       "      <th>author2_givenname</th>\n",
       "      <th>gender_author1</th>\n",
       "      <th>...</th>\n",
       "      <th>tragedy</th>\n",
       "      <th>children</th>\n",
       "      <th>regency</th>\n",
       "      <th>manners</th>\n",
       "      <th>philosophical</th>\n",
       "      <th>coming-of-age</th>\n",
       "      <th>filename</th>\n",
       "      <th>shape</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tl566</td>\n",
       "      <td>hz542</td>\n",
       "      <td>ja532</td>\n",
       "      <td>813</td>\n",
       "      <td>1910</td>\n",
       "      <td>Leblanc</td>\n",
       "      <td>Maurice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Leblanc_813.txt</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gc386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A Strange Disappearance</td>\n",
       "      <td>1998</td>\n",
       "      <td>Green</td>\n",
       "      <td>Anna Katharine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>GreenAnnaKatharine_AStrangeDisappearance.txt</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nca28</td>\n",
       "      <td>tl566</td>\n",
       "      <td>stw43</td>\n",
       "      <td>A Study in Scarlet</td>\n",
       "      <td>1887</td>\n",
       "      <td>Conan Doyle</td>\n",
       "      <td>Arthur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ConanDoyle_AStudyInScarlet.txt</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jc2739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Agatha Webb</td>\n",
       "      <td>1899</td>\n",
       "      <td>Green</td>\n",
       "      <td>Anna Katharine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Green_AgathaWebb.txt</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lcc82</td>\n",
       "      <td>yk499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carmilla</td>\n",
       "      <td>1872</td>\n",
       "      <td>Le_Fanu</td>\n",
       "      <td>Joseph Sheridan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Carmilla.txt</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>jc2739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This Side of Paradise</td>\n",
       "      <td>1920</td>\n",
       "      <td>Fitzgerald</td>\n",
       "      <td>F. Scott</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Fitzgerald_ThisSideOfParadise.txt</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>vs339</td>\n",
       "      <td>thh55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Kill A Mockingbird</td>\n",
       "      <td>1960</td>\n",
       "      <td>Lee</td>\n",
       "      <td>Harper</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Lee_ToKillAMockingbird.txt</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>fhh26</td>\n",
       "      <td>gs542</td>\n",
       "      <td>tj256</td>\n",
       "      <td>Twenty Thousand Leagues Under the Sea</td>\n",
       "      <td>1870</td>\n",
       "      <td>Verne</td>\n",
       "      <td>Jules</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Verne_TwentyThousandLeagues.txt</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>dgr73</td>\n",
       "      <td>jlp367</td>\n",
       "      <td>kg428</td>\n",
       "      <td>Uncle Tom's Cabin</td>\n",
       "      <td>1852</td>\n",
       "      <td>Stowe</td>\n",
       "      <td>Harriet Beecher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Stowe_UncleTom_sCabin.txt</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>cl2264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Voodoo Planet</td>\n",
       "      <td>1959</td>\n",
       "      <td>Norton</td>\n",
       "      <td>Andre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Norton_VoodooPlanet.txt</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 check_1 check_2                                  title  year  \\\n",
       "0       tl566   hz542   ja532                                    813  1910   \n",
       "1       gc386     NaN     NaN                A Strange Disappearance  1998   \n",
       "2       nca28   tl566   stw43                     A Study in Scarlet  1887   \n",
       "3      jc2739     NaN     NaN                            Agatha Webb  1899   \n",
       "4       lcc82   yk499     NaN                               Carmilla  1872   \n",
       "..        ...     ...     ...                                    ...   ...   \n",
       "73     jc2739     NaN     NaN                  This Side of Paradise  1920   \n",
       "74      vs339   thh55     NaN                  To Kill A Mockingbird  1960   \n",
       "75      fhh26   gs542   tj256  Twenty Thousand Leagues Under the Sea  1870   \n",
       "76      dgr73  jlp367   kg428                      Uncle Tom's Cabin  1852   \n",
       "77     cl2264     NaN     NaN                          Voodoo Planet  1959   \n",
       "\n",
       "   author1_surname author1_givenname author2_surname author2_givenname  \\\n",
       "0          Leblanc           Maurice             NaN               NaN   \n",
       "1            Green    Anna Katharine             NaN               NaN   \n",
       "2      Conan Doyle            Arthur             NaN               NaN   \n",
       "3            Green    Anna Katharine             NaN               NaN   \n",
       "4          Le_Fanu   Joseph Sheridan             NaN               NaN   \n",
       "..             ...               ...             ...               ...   \n",
       "73      Fitzgerald          F. Scott             NaN               NaN   \n",
       "74             Lee            Harper             NaN               NaN   \n",
       "75           Verne             Jules             NaN               NaN   \n",
       "76           Stowe   Harriet Beecher             NaN               NaN   \n",
       "77          Norton             Andre             NaN               NaN   \n",
       "\n",
       "   gender_author1  ... tragedy children regency manners philosophical  \\\n",
       "0            male  ...   False    False   False   False         False   \n",
       "1          female  ...   False    False   False   False         False   \n",
       "2            male  ...   False    False   False   False         False   \n",
       "3          female  ...   False    False   False   False         False   \n",
       "4            male  ...   False    False   False   False         False   \n",
       "..            ...  ...     ...      ...     ...     ...           ...   \n",
       "73           male  ...   False    False   False   False         False   \n",
       "74         female  ...   False    False   False   False         False   \n",
       "75           male  ...   False    False   False   False         False   \n",
       "76         female  ...   False    False   False   False         False   \n",
       "77         female  ...   False    False   False   False         False   \n",
       "\n",
       "    coming-of-age                                      filename  shape y_pred  \\\n",
       "0           False                               Leblanc_813.txt  train    NaN   \n",
       "1           False  GreenAnnaKatharine_AStrangeDisappearance.txt  train    NaN   \n",
       "2           False                ConanDoyle_AStudyInScarlet.txt  train    NaN   \n",
       "3           False                          Green_AgathaWebb.txt  train    NaN   \n",
       "4           False                                  Carmilla.txt  train    NaN   \n",
       "..            ...                                           ...    ...    ...   \n",
       "73           True             Fitzgerald_ThisSideOfParadise.txt   test    1.0   \n",
       "74          False                    Lee_ToKillAMockingbird.txt   test    1.0   \n",
       "75          False               Verne_TwentyThousandLeagues.txt   test    1.0   \n",
       "76          False                     Stowe_UncleTom_sCabin.txt   test    1.0   \n",
       "77          False                       Norton_VoodooPlanet.txt   test    1.0   \n",
       "\n",
       "    y  \n",
       "0   1  \n",
       "1   1  \n",
       "2   1  \n",
       "3   1  \n",
       "4   0  \n",
       ".. ..  \n",
       "73  1  \n",
       "74  1  \n",
       "75  1  \n",
       "76  1  \n",
       "77  1  \n",
       "\n",
       "[158 rows x 37 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['shape']='train'\n",
    "testing_data['shape']='test'\n",
    "books_order=pd.concat([training_data, testing_data])\n",
    "books_order['y']=labels\n",
    "books_order['gender_author1']=books_order['gender_author1'].str.lower()\n",
    "books_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: mp2\n",
    "coords_books = TruncatedSVD(n_components=2).fit_transform(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4. Results and discussion (40 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# few paragraphs\n",
    "# realistic - 3 results\n",
    "# figure, table, accuracy table\n",
    "# analyze each of the results, one paragraph at the end how they fit together\n",
    "# group -- a bit more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Reflection (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Resources consulted (0 points, but -5 if missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pre_proc()`: MP 02, INFO 3350 <br>\n",
    "`compare_scores()`: MP 02, INFO 3350<br>\n",
    "Feature importance for sklearn Naive Bayes: https://stackoverflow.com/questions/12618030/how-to-replace-back-slash-character-with-empty-string-in-python<br>\n",
    "SVD Scatterplot: MP 02, INFO 3350"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Responsibility statement (0 points, but -5 if missing)\n",
    "**See separate CMS assignment 'MP 03: Responsibility statement'.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
